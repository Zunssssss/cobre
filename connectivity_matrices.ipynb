{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction and plotting\n",
    "\n",
    "Here I read the atlas partitioned datasets and calculate the connectivity matrix for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import os.path           as     op\n",
    "import numpy             as     np\n",
    "import matplotlib.pyplot as     plt\n",
    "import seaborn           as     sns\n",
    "from   functools         import partial\n",
    "from   natsort           import natsorted\n",
    "from   collections       import OrderedDict\n",
    "\n",
    "from   boyle.storage            import (get_dataset_names, get_group_names, get_datasets, \n",
    "                                        save_variables_to_hdf5, extract_datasets)\n",
    "from   luigi.similarity_measure import SimilarityMeasureFactory\n",
    "from   luigi.selection          import TimeSeriesSelectorFactory\n",
    "from   luigi.connectivity       import build_timeseries, transform_timeseries, calculate_connectivity\n",
    "\n",
    "from   fabfile                  import get_subject_labels, get_filtered_subjects_ids_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timeseries_h5path     = '/Users/alexandre/Projects/bcc/cobre/cobre_partitioned_timeseries.hdf5'\n",
    "\n",
    "TR                    = 2\n",
    "build_timeseries      = partial(build_timeseries, sampling_interval=TR, pre_filter=None, normalize=None)\n",
    "\n",
    "aalts_groupname       = '/pipe_wtemp_noglob_aal_3mm_func_timeseries'\n",
    "aalconns_groupname    = '/pipe_wtemp_noglob_aal_3mm_connectivities'\n",
    "subj_groups           = get_group_names(timeseries_h5path, aalts_groupname)\n",
    "file_groups           = get_group_names(timeseries_h5path, '/')\n",
    "\n",
    "subj_ids, subj_labels = get_filtered_subjects_ids_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject_timeseries(h5file_path, subj_path, sampling_interval=TR):\n",
    "    \"\"\"Return the timeseries of one subject in a HDF5 file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h5file_path: str\n",
    "        Path to the hdf5 file with the subject timeseries.\n",
    "    \n",
    "    subj_path: str\n",
    "        HDF5 internal path to the subject.\n",
    "\n",
    "    sampling_interval: int or float\n",
    "        Timeseries sampling interval in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries: OrderedDict of nitime.timeseries.TimeSeries\n",
    "        A dictionary with all the partition timeseries of the subject.\n",
    "    \"\"\"\n",
    "    timeseries = OrderedDict()\n",
    "    with h5py.File(h5file_path, mode='r') as timeseries_file:\n",
    "        dspaths    = natsorted(get_dataset_names(timeseries_file, subj_path))\n",
    "        for dspath in dspaths:\n",
    "            timeseries[dspath.split('/')[-1]] = build_timeseries(timeseries_file[dspath][:], \n",
    "                                                                 sampling_interval=sampling_interval)\n",
    "\n",
    "    return timeseries\n",
    "\n",
    "def get_connectivity_matrix(timeseries, selection_method, similarity_measure):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries: dict or list of (nitime.timeseries.TimeSeries or numpy.ndarray)\n",
    "        The N sets of timeseries of one subject.\n",
    "        \n",
    "    selection_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.selection.TimeSeriesSelectorFactory.create_method` more information and the possible choices.\n",
    "    \n",
    "    similarity_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.similarity_measure.SimilarityMeasureFactory.create_method` for more information and\n",
    "        the possible choices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    connectivity: numpy.ndarray\n",
    "        Matrix of shape (N, N)\n",
    "    \"\"\"\n",
    "    selection  = TimeSeriesSelectorFactory.create_method(selection_method)\n",
    "    similarity = SimilarityMeasureFactory. create_method(similarity_measure)\n",
    "\n",
    "    # transform_timeseries(timeseries, selection_method, **kwargs)\n",
    "    transformed_timeseries = transform_timeseries  (timeseries, selection)\n",
    "\n",
    "    # calculate_connectivity(timeseries_set, measure, sampling_interval, lb=0, ub=None, **kwargs):\n",
    "    return calculate_connectivity(transformed_timeseries, similarity, sampling_interval=TR)\n",
    "\n",
    "\n",
    "def create_group_connectivites(timeseries_h5path, subj_groups, selection_method, similarity_measure):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries_h5path: str\n",
    "\n",
    "    subj_groups: list of str\n",
    "\n",
    "    selection_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.selection.TimeSeriesSelectorFactory.create_method` more information and the possible choices.\n",
    "    \n",
    "    similarity_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.similarity_measure.SimilarityMeasureFactory.create_method` for more information and\n",
    "        the possible choices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    connectivities: dict\n",
    "        Dictionary with subj_id -> connectivity_matrix\n",
    "    \"\"\"\n",
    "    connectivities = OrderedDict()\n",
    "\n",
    "    for subj_path in subj_groups:\n",
    "        timeseries   = get_subject_timeseries  (timeseries_h5path, subj_path)\n",
    "        connectivity = get_connectivity_matrix (timeseries, selection_method, similarity_measure)\n",
    "        connectivities[subj_path.split('/')[-1]] = connectivity\n",
    "\n",
    "    return connectivites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_connectivity_matrix(x, title=None, show_ticklabels=False):\n",
    "    sns.set(context=\"paper\", font=\"monospace\")\n",
    "    #sns.set(style=\"darkgrid\")\n",
    "    #sns.set(rc={\"figure.figsize\": (6, 6)})\n",
    "    fig, ax = plt.subplots()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    #sns.corrplot(x, annot=False, sig_stars=False, diag_names=False, cmap=cmap, ax=ax)\n",
    "    sns.heatmap(x, linewidths=0, square=True, cmap=cmap)\n",
    "\n",
    "    #plt.imshow(x, cmap='jet', interpolation='nearest')\n",
    "    plt.setp(ax.get_yticklabels(), visible=show_ticklabels)\n",
    "    plt.setp(ax.get_xticklabels(), visible=show_ticklabels)\n",
    "    #if not show_ticklabels:\n",
    "        #ax.set_xticklabels([])\n",
    "        #ax.set_yticklabels([])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "#plot_connectivity_matrix(connectivity, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_connectivity_matrices(timeseries_h5path, selection_method, similarity_measure):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    selection_method: str\n",
    "    \n",
    "    similarity_measure: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    connectivities:\n",
    "\n",
    "    \"\"\"\n",
    "    if aalconns_groupname in file_groups:\n",
    "        connectivities = extract_datasets(timeseries_h5path, aalconns_groupname)\n",
    "    else:\n",
    "        print('Calculating connectivity matrices using {} and {}.'.format(selection_method, similarity_measure))\n",
    "        connectivities = create_group_connectivites(timeseries_h5path, subj_groups, selection_method, similarity_measure)\n",
    "\n",
    "        # save the connectivity matrices into the hdf file\n",
    "        save_variables_to_hdf5(timeseries_h5path, \n",
    "                           {'{}-{}'.format(selection_method, similarity_measure): connectivities},\n",
    "                           mode='a', \n",
    "                           h5path= aalconns_groupname)\n",
    "\n",
    "    return connectivities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from functools      import partial\n",
    "from boyle.parallel import parallel_function\n",
    "\n",
    "selection_method   = 'eigen'\n",
    "similarity_measure = 'mean_coherence'\n",
    "\n",
    "def get_connectivity(timeseries_h5path, subj_path, selection_method, similarity_measure):\n",
    "    timeseries = get_subject_timeseries(timeseries_h5path, subj_path)\n",
    "    return get_connectivity_matrix(timeseries, selection_method, similarity_measure)\n",
    "\n",
    "\n",
    "get_my_connectivities = partial(get_connectivity, timeseries_file=timeseries_h5path, \n",
    "                                selection_method=selection_method, similarity_measure=similarity_measure)\n",
    "\n",
    "get_my_connectivities.parallel = parallel_function(get_my_connectivities, n_cpus=3)\n",
    "\n",
    "start = time()\n",
    "conns = get_my_connectivities.parallel(subj_groups)\n",
    "\n",
    "connectivities = OrderedDict()\n",
    "for subj_path, conn in zip(subj_groups, conns):\n",
    "    connectivities[subj_path.split('/')[-1]] = conn\n",
    "\n",
    "parallel_time = time() - start\n",
    "print('parallel_time: {}'.format(parallel_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for conn in connectivities:\n",
    "#    plot_connectivity_matrix(connectivities[conn], conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_lower_triangular_matrix(x, k=0):\n",
    "    \"\"\"Return the lower triangular values of x without the main diagonal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy.ndarray\n",
    "        2D square matrix\n",
    "\n",
    "    k : int, optional\n",
    "        Diagonal above which to zero elements. \n",
    "        k = 0 (the default) is the main diagonal, \n",
    "        k < 0 is below it and \n",
    "        k > 0 is above.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features: numpy.ndarray\n",
    "        vector\n",
    "    \"\"\"\n",
    "    return x[np.tril_indices_from(x, k=k)]\n",
    "\n",
    "\n",
    "def number_of_triangular_elements(x, k=0):\n",
    "    \"\"\"Return the number of elements that the lower triangular matrix of x has.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy.ndarray\n",
    "        2D square matrix\n",
    "\n",
    "    k : int, optional\n",
    "        Diagonal above which to zero elements. \n",
    "        k = 0 (the default) is the main diagonal, \n",
    "        k < 0 is below it and \n",
    "        k > 0 is above.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n_elems: int\n",
    "        number of elements in the triangular matrix\n",
    "    \"\"\"\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        raise TypeError('Expected a numpy.ndarray, got a {}.'.format(type(x)))\n",
    "\n",
    "    if x.ndim != 2:\n",
    "        raise TypeError('Expected a 2D matrix, got a matrix with {} dimensions.'.format(x.ndim))\n",
    "\n",
    "    if x.shape[0] != x.shape[1]:\n",
    "        raise TypeError('Expected a square matrix, got a matrix with shape {}'.format(x.shape))\n",
    "\n",
    "    if k == 0:\n",
    "        rows    = x.shape[1]\n",
    "        n_elems = 0.5 * ((rows + 1) * rows)\n",
    "    else:\n",
    "        ones    = np.ones_like(x)\n",
    "        n_elems = np.sum(np.tril(ones, k=k)) \n",
    "    \n",
    "    return int(n_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ClassificationResult(predictions=[0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0], probabilities=None, cv_targets=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0], best_parameters=OrderedDict([(0, {'C': 0.01}), (1, {'C': 0.01}), (2, {'C': 0.01}), (3, {'C': 0.1}), (4, {'C': 0.01}), (5, {'C': 0.01}), (6, {'C': 0.01}), (7, {'C': 0.01}), (8, {'C': 0.01}), (9, {'C': 0.01}), (10, {'C': 0.01}), (11, {'C': 0.01}), (12, {'C': 0.01}), (13, {'C': 0.01}), (14, {'C': 0.01}), (15, {'C': 0.01}), (16, {'C': 0.01}), (17, {'C': 0.01}), (18, {'C': 0.01}), (19, {'C': 0.01}), (20, {'C': 0.01}), (21, {'C': 0.01}), (22, {'C': 0.01}), (23, {'C': 0.01}), (24, {'C': 0.01}), (25, {'C': 0.01}), (26, {'C': 0.01}), (27, {'C': 0.01}), (28, {'C': 0.01}), (29, {'C': 0.01}), (30, {'C': 0.01}), (31, {'C': 0.01}), (32, {'C': 0.01}), (33, {'C': 0.01}), (34, {'C': 0.01}), (35, {'C': 0.01}), (36, {'C': 0.01}), (37, {'C': 0.01}), (38, {'C': 0.1}), (39, {'C': 0.01}), (40, {'C': 0.01}), (41, {'C': 0.01}), (42, {'C': 0.01}), (43, {'C': 0.1}), (44, {'C': 0.01}), (45, {'C': 0.01}), (46, {'C': 0.01}), (47, {'C': 0.01}), (48, {'C': 0.01}), (49, {'C': 0.01}), (50, {'C': 0.1}), (51, {'C': 0.01}), (52, {'C': 0.01}), (53, {'C': 0.01}), (54, {'C': 0.01}), (55, {'C': 0.01}), (56, {'C': 0.01}), (57, {'C': 0.01}), (58, {'C': 0.01}), (59, {'C': 0.01}), (60, {'C': 0.01}), (61, {'C': 0.01}), (62, {'C': 0.01}), (63, {'C': 0.01}), (64, {'C': 0.1}), (65, {'C': 0.01}), (66, {'C': 0.01}), (67, {'C': 0.01}), (68, {'C': 0.01}), (69, {'C': 0.01}), (70, {'C': 0.01}), (71, {'C': 0.01}), (72, {'C': 0.01}), (73, {'C': 0.01}), (74, {'C': 0.01}), (75, {'C': 0.01}), (76, {'C': 0.01}), (77, {'C': 0.01}), (78, {'C': 0.01}), (79, {'C': 0.01}), (80, {'C': 0.01}), (81, {'C': 0.01}), (82, {'C': 0.01}), (83, {'C': 0.01}), (84, {'C': 0.01}), (85, {'C': 0.01}), (86, {'C': 0.1}), (87, {'C': 0.01}), (88, {'C': 0.01}), (89, {'C': 0.01}), (90, {'C': 0.1}), (91, {'C': 0.01}), (92, {'C': 0.1}), (93, {'C': 0.01}), (94, {'C': 0.01}), (95, {'C': 0.01}), (96, {'C': 0.01}), (97, {'C': 0.01}), (98, {'C': 0.1}), (99, {'C': 0.01}), (100, {'C': 0.01}), (101, {'C': 0.01}), (102, {'C': 0.01}), (103, {'C': 0.1}), (104, {'C': 0.01}), (105, {'C': 0.01}), (106, {'C': 0.01}), (107, {'C': 0.1}), (108, {'C': 0.01}), (109, {'C': 0.01}), (110, {'C': 0.01}), (111, {'C': 0.01}), (112, {'C': 0.01}), (113, {'C': 0.01}), (114, {'C': 0.01}), (115, {'C': 0.01}), (116, {'C': 0.01}), (117, {'C': 0.01}), (118, {'C': 0.1}), (119, {'C': 0.01}), (120, {'C': 0.01}), (121, {'C': 0.01}), (122, {'C': 0.01}), (123, {'C': 0.01}), (124, {'C': 0.01}), (125, {'C': 0.01}), (126, {'C': 0.01}), (127, {'C': 0.01}), (128, {'C': 0.01}), (129, {'C': 0.01}), (130, {'C': 0.01}), (131, {'C': 0.01}), (132, {'C': 0.01}), (133, {'C': 0.01}), (134, {'C': 0.01}), (135, {'C': 0.01}), (136, {'C': 0.01}), (137, {'C': 0.01}), (138, {'C': 0.01}), (139, {'C': 0.01}), (140, {'C': 0.01}), (141, {'C': 0.01}), (142, {'C': 0.01}), (143, {'C': 0.01}), (144, {'C': 0.01})]), cv_folds=sklearn.cross_validation.LeaveOneOut(n=145), features_importance=None, targets=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0]), labels=[0, 1]),\n",
       " ClassificationMetrics(accuracy=0.62758620689655176, sensitivity=0.64383561643835618, specificity=0.61111111111111116, precision=0.62666666666666671, f1_score=0.6351351351351352, area_under_curve=0.62747336377473362))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from darwin.pipeline import ClassificationPipeline\n",
    "\n",
    "# Diagonal above which to zero elements.\n",
    "k = -1\n",
    "\n",
    "# create the samples matrix\n",
    "sample     = next (iter (connectivities.values()))\n",
    "n_subjects = len(connectivities)\n",
    "n_features = number_of_triangular_elements(sample, k=k)\n",
    "\n",
    "feature_matrix = np.zeros((n_subjects, n_features), dtype=sample.dtype)\n",
    "\n",
    "# get the data\n",
    "selection_method   = 'eigen'\n",
    "similarity_measure = 'mean_coherence'\n",
    "connectivities = get_connectivity_matrices(timeseries_h5path, selection_method, similarity_measure)\n",
    "\n",
    "# fill the feature matrix\n",
    "for idx, conn in enumerate(connectivities):\n",
    "    feature_matrix[idx, :] = extract_lower_triangular_matrix(connectivities[conn], k=k)\n",
    "\n",
    "# -- test with darwin\n",
    "# 'RandomForestClassifier', 'RBFSVC', 'LinearSVC', 'GMM', \n",
    "classifier_name = 'LinearSVC' #'linsvm'\n",
    "cvmethod = 'loo'\n",
    "\n",
    "pipe = ClassificationPipeline(clfmethod=classifier_name, cvmethod=cvmethod)\n",
    "\n",
    "eprint('Classifying')\n",
    "pipe.cross_validation(feature_matrix, np.array(subj_labels))\n",
    "#results, metrics = pipe.cross_validation(feature_matrix, np.array(subj_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
