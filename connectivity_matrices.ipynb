{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Connectivity matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction and plotting\n",
    "\n",
    "Here I read the atlas partitioned datasets and calculate the connectivity matrix for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import os.path           as     op\n",
    "import numpy             as     np\n",
    "import matplotlib.pyplot as     plt\n",
    "import seaborn           as     sns\n",
    "from   functools         import partial\n",
    "from   natsort           import natsorted\n",
    "from   collections       import OrderedDict\n",
    "\n",
    "from   boyle.storage            import (get_dataset_names, get_group_names, get_datasets, \n",
    "                                        save_variables_to_hdf5, extract_datasets)\n",
    "from   luigi.similarity_measure import SimilarityMeasureFactory\n",
    "from   luigi.selection          import TimeSeriesSelectorFactory\n",
    "from   luigi.connectivity       import build_timeseries, transform_timeseries, calculate_connectivity\n",
    "\n",
    "from   fabfile                  import get_subject_labels, get_filtered_subjects_ids_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SETUP LOGGING AND AUTO TRACER\n",
    "# THIS CELL MUST BE SECOND IN POSITION\n",
    "import logging\n",
    "from   autologging import TRACE, traced\n",
    "\n",
    "logger    = logging.getLogger()\n",
    "shandler  = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "shandler.setFormatter(formatter)\n",
    "logger.addHandler(shandler)\n",
    "logger.setLevel(TRACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabfile.py read_subject_ids_file: DEBUG Reading list of subject ids from file /Users/alexandre/Projects/bcc/cobre/subject_list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015-05-26 14:02:05,154 - fabfile - DEBUG - Reading list of subject ids from file /Users/alexandre/Projects/bcc/cobre/subject_list.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fabfile.py get_filtered_subjects_ids_and_labels: DEBUG Filtering list of files using subjects ids from subject ids file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2015-05-26 14:02:05,158 - fabfile - DEBUG - Filtering list of files using subjects ids from subject ids file.\n"
     ]
    }
   ],
   "source": [
    "work_dir              = '/Users/alexandre/Projects/bcc/cobre/'\n",
    "timeseries_h5path     = op.join(work_dir, 'cobre_partitioned_timeseries.hdf5')\n",
    "\n",
    "TR                    = 2\n",
    "build_timeseries      = partial(build_timeseries, sampling_interval=TR, pre_filter=None, normalize=None)\n",
    "\n",
    "aalts_groupname       = '/pipe_wtemp_noglob_aal_3mm_func_timeseries'\n",
    "aalconns_groupname    = '/pipe_wtemp_noglob_aal_3mm_connectivities'\n",
    "subj_groups           = get_group_names(timeseries_h5path, aalts_groupname)\n",
    "\n",
    "subj_ids, subj_labels = get_filtered_subjects_ids_and_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@traced\n",
    "def get_subject_timeseries(h5file_path, subj_path, sampling_interval=TR):\n",
    "    \"\"\"Return the timeseries of one subject in a HDF5 file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h5file_path: str\n",
    "        Path to the hdf5 file with the subject timeseries.\n",
    "    \n",
    "    subj_path: str\n",
    "        HDF5 internal path to the subject.\n",
    "\n",
    "    sampling_interval: int or float\n",
    "        Timeseries sampling interval in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeseries: OrderedDict of nitime.timeseries.TimeSeries\n",
    "        A dictionary with all the partition timeseries of the subject.\n",
    "    \"\"\"\n",
    "    #log.debug({}get_subject_timeseries.func_code.co_varnames)\n",
    "    timeseries = OrderedDict()\n",
    "    with h5py.File(h5file_path, mode='r') as timeseries_file:\n",
    "        dspaths    = natsorted(get_dataset_names(timeseries_file, subj_path))\n",
    "        for dspath in dspaths:\n",
    "            timeseries[dspath.split('/')[-1]] = build_timeseries(timeseries_file[dspath][:], \n",
    "                                                                 sampling_interval=sampling_interval)\n",
    "\n",
    "    return timeseries\n",
    "\n",
    "\n",
    "@traced\n",
    "def get_connectivity_matrix(timeseries, selection_method, similarity_measure):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries: dict or list of (nitime.timeseries.TimeSeries or numpy.ndarray)\n",
    "        The N sets of timeseries of one subject.\n",
    "        \n",
    "    selection_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.selection.TimeSeriesSelectorFactory.create_method` more information and the possible choices.\n",
    "    \n",
    "    similarity_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.similarity_measure.SimilarityMeasureFactory.create_method` for more information and\n",
    "        the possible choices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    connectivity: numpy.ndarray\n",
    "        Matrix of shape (N, N)\n",
    "    \"\"\"\n",
    "    selection  = TimeSeriesSelectorFactory.create_method(selection_method)\n",
    "    similarity = SimilarityMeasureFactory. create_method(similarity_measure)\n",
    "\n",
    "    # transform_timeseries(timeseries, selection_method, **kwargs)\n",
    "    transformed_timeseries = transform_timeseries  (timeseries, selection)\n",
    "\n",
    "    # calculate_connectivity(timeseries_set, measure, sampling_interval, lb=0, ub=None, **kwargs):\n",
    "    return calculate_connectivity(transformed_timeseries, similarity, sampling_interval=TR)\n",
    "\n",
    "\n",
    "@traced\n",
    "def create_group_connectivites(timeseries_h5path, subj_groups, selection_method, similarity_measure):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries_h5path: str\n",
    "\n",
    "    subj_groups: list of str\n",
    "\n",
    "    selection_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.selection.TimeSeriesSelectorFactory.create_method` more information and the possible choices.\n",
    "    \n",
    "    similarity_method: str\n",
    "        The name of the timeseries set transformation method.\n",
    "        See `luigi.similarity_measure.SimilarityMeasureFactory.create_method` for more information and\n",
    "        the possible choices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    connectivities: dict\n",
    "        Dictionary with subj_id -> connectivity_matrix\n",
    "    \"\"\"\n",
    "    connectivities = OrderedDict()\n",
    "\n",
    "    for subj_path in subj_groups:\n",
    "        timeseries   = get_subject_timeseries  (timeseries_h5path, subj_path)\n",
    "        connectivity = get_connectivity_matrix (timeseries, selection_method, similarity_measure)\n",
    "        connectivities[subj_path.split('/')[-1]] = connectivity\n",
    "\n",
    "    return connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_connectivity_matrix(x, title=None, show_ticklabels=False):\n",
    "    sns.set(context=\"paper\", font=\"monospace\")\n",
    "    #sns.set(style=\"darkgrid\")\n",
    "    #sns.set(rc={\"figure.figsize\": (6, 6)})\n",
    "    fig, ax = plt.subplots()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    #sns.corrplot(x, annot=False, sig_stars=False, diag_names=False, cmap=cmap, ax=ax)\n",
    "    sns.heatmap(x, linewidths=0, square=True, cmap=cmap)\n",
    "\n",
    "    #plt.imshow(x, cmap='jet', interpolation='nearest')\n",
    "    plt.setp(ax.get_yticklabels(), visible=show_ticklabels)\n",
    "    plt.setp(ax.get_xticklabels(), visible=show_ticklabels)\n",
    "    #if not show_ticklabels:\n",
    "        #ax.set_xticklabels([])\n",
    "        #ax.set_yticklabels([])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "#plot_connectivity_matrix(connectivity, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@traced\n",
    "def get_connectivity_matrices(timeseries_h5path, connmats_grouppath, selection_method, similarity_measure, \n",
    "                              save_in_hdf=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeseries_h5path: str\n",
    "        Path to the timeseries hdf5 file\n",
    "    \n",
    "    connmats_grouppath: str\n",
    "        HDF5 group path to the group where the connectivity matrices for \n",
    "        the selection_method and similarity_matrices are stored\n",
    "    \n",
    "    selection_method: str\n",
    "        Choices:\n",
    "        methods = OrderedDict([ ('mean',          MeanTimeSeries),\n",
    "                                ('eigen',         EigenTimeSeries),\n",
    "                                ('ilsia',         ILSIATimeSeries),\n",
    "                                ('cca',           CCATimeSeries),\n",
    "                                ('filtered',      FilteredTimeSeries),\n",
    "                                ('filtered_mean', MeanFilteredTimeSeries),\n",
    "                                ('filered_eigen', EigenFilteredTimeSeries)])\n",
    "    similarity_measure: str\n",
    "        Choices:\n",
    "        methods = OrderedDict([ ('correlation',          CorrelationMeasure),\n",
    "                                ('coherence',            NiCoherenceMeasure),\n",
    "                                ('grangercausality',     NiGrangerCausalityMeasure),\n",
    "                                ('nicorrelation',        NiCorrelationMeasure),\n",
    "                                ('seedcorrelation',      SeedCorrelationMeasure),\n",
    "                                ('seedcoherence',        SeedCoherenceMeasure),\n",
    "                                ('mean_coherence',       MeanCoherenceMeasure),\n",
    "                                ('mean_seedcoherence',   MeanSeedCoherenceMeasure),\n",
    "                                ('mean_seedcorrelation', MeanSeedCorrelationMeasure)])\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    connectivities: \n",
    "\n",
    "    \"\"\"\n",
    "    #from IPython.core.debugger import Tracer\n",
    "    #Tracer()()\n",
    "    \n",
    "    file_groups = get_group_names(timeseries_h5path, aalconns_groupname)\n",
    "   \n",
    "    if connmats_grouppath in file_groups:\n",
    "        \n",
    "        connectivities = extract_datasets(timeseries_h5path, connmats_grouppath)\n",
    "    else:\n",
    "        try:\n",
    "            print('Calculating connectivity matrices using {} and {}.'.format(selection_method, similarity_measure))\n",
    "            connectivities = create_group_connectivites(timeseries_h5path, subj_groups, \n",
    "                                                        selection_method, similarity_measure)\n",
    "        except:\n",
    "            print('Error calculating connectivity matrices using {} and {}.'.format(selection_method, \n",
    "                                                                                    similarity_measure))\n",
    "            raise\n",
    "        else:\n",
    "            # save the connectivity matrices into the hdf file\n",
    "            save_variables_to_hdf5(timeseries_h5path, \n",
    "                                   {'{}-{}'.format(selection_method, similarity_measure): connectivities},\n",
    "                                   mode='a', \n",
    "                                   h5path=connmats_grouppath)\n",
    "\n",
    "    return connectivities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from functools      import partial\n",
    "from boyle.parallel import parallel_function\n",
    "\n",
    "selection_method   = 'eigen'\n",
    "similarity_measure = 'mean_coherence'\n",
    "\n",
    "def get_connectivity(timeseries_h5path, subj_path, selection_method, similarity_measure):\n",
    "    timeseries = get_subject_timeseries(timeseries_h5path, subj_path)\n",
    "    return get_connectivity_matrix(timeseries, selection_method, similarity_measure)\n",
    "\n",
    "\n",
    "get_my_connectivities = partial(get_connectivity, timeseries_file=timeseries_h5path, \n",
    "                                selection_method=selection_method, similarity_measure=similarity_measure)\n",
    "\n",
    "get_my_connectivities.parallel = parallel_function(get_my_connectivities, n_cpus=3)\n",
    "\n",
    "start = time()\n",
    "conns = get_my_connectivities.parallel(subj_groups)\n",
    "\n",
    "connectivities = OrderedDict()\n",
    "for subj_path, conn in zip(subj_groups, conns):\n",
    "    connectivities[subj_path.split('/')[-1]] = conn\n",
    "\n",
    "parallel_time = time() - start\n",
    "print('parallel_time: {}'.format(parallel_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for conn in connectivities:\n",
    "#    plot_connectivity_matrix(connectivities[conn], conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from nitime.viz import drawmatrix_channels\n",
    "\n",
    "#for conn in connectivities:\n",
    "#    drawmatrix_channels(connectivities[conn], [], size=[10., 10.], color_anchor=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_lower_triangular_matrix(x, k=0):\n",
    "    \"\"\"Return the lower triangular values of x without the main diagonal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy.ndarray\n",
    "        2D square matrix\n",
    "\n",
    "    k : int, optional\n",
    "        Diagonal above which to zero elements. \n",
    "        k = 0 (the default) is the main diagonal, \n",
    "        k < 0 is below it and \n",
    "        k > 0 is above.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features: numpy.ndarray\n",
    "        vector\n",
    "    \"\"\"\n",
    "    return x[np.tril_indices_from(x, k=k)]\n",
    "\n",
    "\n",
    "def number_of_triangular_elements(x, k=0):\n",
    "    \"\"\"Return the number of elements that the lower triangular matrix of x has.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: numpy.ndarray\n",
    "        2D square matrix\n",
    "\n",
    "    k : int, optional\n",
    "        Diagonal above which to zero elements. \n",
    "        k = 0 (the default) is the main diagonal, \n",
    "        k < 0 is below it and \n",
    "        k > 0 is above.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n_elems: int\n",
    "        number of elements in the triangular matrix\n",
    "    \"\"\"\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        raise TypeError('Expected a numpy.ndarray, got a {}.'.format(type(x)))\n",
    "\n",
    "    if x.ndim != 2:\n",
    "        raise TypeError('Expected a 2D matrix, got a matrix with {} dimensions.'.format(x.ndim))\n",
    "\n",
    "    if x.shape[0] != x.shape[1]:\n",
    "        raise TypeError('Expected a square matrix, got a matrix with shape {}'.format(x.shape))\n",
    "\n",
    "    if k == 0:\n",
    "        rows    = x.shape[1]\n",
    "        n_elems = 0.5 * ((rows + 1) * rows)\n",
    "    else:\n",
    "        ones    = np.ones_like(x)\n",
    "        n_elems = np.sum(np.tril(ones, k=k)) \n",
    "    \n",
    "    return int(n_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@traced\n",
    "def create_cobre_connmat_featuresets(timeseries_h5path, connmats_grouppath, selection_method, similarity_measure):\n",
    "    # Diagonal above which to zero elements.\n",
    "    k = -1\n",
    "\n",
    "    # get the data\n",
    "    connectivities = get_connectivity_matrices(timeseries_h5path, connmats_grouppath, \n",
    "                                               selection_method, similarity_measure)\n",
    "\n",
    "    # create the samples matrix\n",
    "    sample     = next (iter (connectivities.values()))\n",
    "    n_subjects = len(connectivities)\n",
    "    n_features = number_of_triangular_elements(sample, k=k)\n",
    "\n",
    "    feature_matrix = np.zeros((n_subjects, n_features), dtype=sample.dtype)\n",
    "\n",
    "    # fill the feature matrix\n",
    "    for idx, conn in enumerate(connectivities):\n",
    "        feature_matrix[idx, :] = extract_lower_triangular_matrix(connectivities[conn], k=k)\n",
    "\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import ParameterGrid\n",
    "\n",
    "def build_param_grid(*variable_names):\n",
    "    adict = {var: eval(var) for var in variable_names}\n",
    "    return ParameterGrid(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the parameter values grid\n",
    "selection_methods   = ['eigen', 'mean'] #'ilsia', 'cca']\n",
    "similarity_measures = ['correlation', 'coherence', 'grangercausality']\n",
    "classifiers_names   = ['RandomForestClassifier', 'RBFSVC', 'LinearSVC', 'GMM']\n",
    "cvmethod            = 'loo'\n",
    "\n",
    "# similarity measures value ranges\n",
    "sm_value_ranges = {'correlation':      (-1, 1  ),\n",
    "                   'coherence':        (-1, 1  ),\n",
    "                   'grangercausality': ( 0, 0.5),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = build_param_grid('selection_methods', 'similarity_measures', 'classifiers_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting functional matrices data for {'similarity_measures': 'correlation', 'classifiers_names': 'RandomForestClassifier', 'selection_methods': 'eigen'}.\n",
      "Classifying with settings: {'similarity_measures': 'correlation', 'classifiers_names': 'RandomForestClassifier', 'selection_methods': 'eigen'}."
     ]
    }
   ],
   "source": [
    "def classification_experiments():\n",
    "    from darwin.pipeline import ClassificationPipeline\n",
    "\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    results = {}\n",
    "    metrics = {}\n",
    "\n",
    "    for params in param_grid:\n",
    "\n",
    "        selection_method   = params['selection_methods']\n",
    "        similarity_measure = params['similarity_measures']\n",
    "        classifier_name    = params['classifiers_names']\n",
    "\n",
    "        connmats_grouppath = '{}/{}_{}'.format(aalconns_groupname, selection_method, similarity_measure)\n",
    "\n",
    "        # get features\n",
    "        print('Getting functional matrices data for {}.'.format(str(params)))\n",
    "        features = create_cobre_connmat_featuresets(timeseries_h5path, connmats_grouppath, \n",
    "                                                    selection_method, similarity_measure)\n",
    "\n",
    "        # -- test with darwin\n",
    "        pipe = ClassificationPipeline(clfmethod=classifier_name, cvmethod=cvmethod)\n",
    "\n",
    "        print('Classifying with settings: {}.'.format(str(params)))\n",
    "        results[str(params)], metrics[str(params)] = pipe.cross_validation(features, np.array(subj_labels))\n",
    "\n",
    "    return results, metrics\n",
    "\n",
    "\n",
    "import shelve\n",
    "results, metrics = classification_experiments()\n",
    "d = shelve.open(op.join(work_dir, 'classification_results_metrics.shelve'))\n",
    "d['results'] = results\n",
    "d['metrics'] = metrics\n",
    "d.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot connectivity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nitime.viz import make_axes_locatable\n",
    "\n",
    "def drawmatrix_channels(in_m, channel_names=None, fig=None, x_tick_rot=0,\n",
    "                        size=None, cmap=plt.cm.RdBu_r, colorbar=True,\n",
    "                        color_anchor=None, title=None):\n",
    "    \"\"\"Creates a lower-triangle of the matrix of an nxn set of values. This is\n",
    "    the typical format to show a symmetrical bivariate quantity (such as\n",
    "    correlation or coherence between two different ROIs).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    in_m: nxn array with values of relationships between two sets of rois or\n",
    "    channels\n",
    "\n",
    "    channel_names (optional): list of strings with the labels to be applied to\n",
    "    the channels in the input. Defaults to '0','1','2', etc.\n",
    "\n",
    "    fig (optional): a matplotlib figure\n",
    "\n",
    "    cmap (optional): a matplotlib colormap to be used for displaying the values\n",
    "    of the connections on the graph\n",
    "\n",
    "    title (optional): string to title the figure (can be like '$\\alpha$')\n",
    "\n",
    "    color_anchor (optional): determine the mapping from values to colormap\n",
    "        if None, min and max of colormap correspond to min and max of in_m\n",
    "        if 0, min and max of colormap correspond to max of abs(in_m)\n",
    "        if (a,b), min and max of colormap correspond to (a,b)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    fig: a figure object\n",
    "\n",
    "    \"\"\"\n",
    "    N = in_m.shape[0]\n",
    "    ind = np.arange(N)  # the evenly spaced plot indices\n",
    "\n",
    "    def channel_formatter(x, pos=None):\n",
    "        thisind = np.clip(int(x), 0, N - 1)\n",
    "        return channel_names[thisind]\n",
    "\n",
    "    if fig is None:\n",
    "        fig = plt.figure()\n",
    "\n",
    "    if size is not None:\n",
    "\n",
    "        fig.set_figwidth(size[0])\n",
    "        fig.set_figheight(size[1])\n",
    "\n",
    "    w = fig.get_figwidth()\n",
    "    h = fig.get_figheight()\n",
    "\n",
    "    ax_im = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    #If you want to draw the colorbar:\n",
    "    if colorbar:\n",
    "        divider = make_axes_locatable(ax_im)\n",
    "        ax_cb = divider.new_vertical(size=\"10%\", pad=0.1, pack_start=True)\n",
    "        fig.add_axes(ax_cb)\n",
    "\n",
    "    #Make a copy of the input, so that you don't make changes to the original\n",
    "    #data provided\n",
    "    m = in_m.copy()\n",
    "\n",
    "    #Null the upper triangle, so that you don't get the redundant and the\n",
    "    #diagonal values:\n",
    "    idx_null = np.triu_indices(m.shape[0])\n",
    "    m[idx_null] = np.nan\n",
    "\n",
    "    #Extract the minimum and maximum values for scaling of the\n",
    "    #colormap/colorbar:\n",
    "    max_val = np.nanmax(m)\n",
    "    min_val = np.nanmin(m)\n",
    "\n",
    "    if color_anchor is None:\n",
    "        color_min = min_val\n",
    "        color_max = max_val\n",
    "    elif color_anchor == 0:\n",
    "        bound = max(abs(max_val), abs(min_val))\n",
    "        color_min = -bound\n",
    "        color_max = bound\n",
    "    else:\n",
    "        color_min = color_anchor[0]\n",
    "        color_max = color_anchor[1]\n",
    "\n",
    "    #The call to imshow produces the matrix plot:\n",
    "    im = ax_im.imshow(m, origin='upper', interpolation='nearest',\n",
    "       vmin=color_min, vmax=color_max, cmap=cmap)\n",
    "\n",
    "    #Formatting:\n",
    "    ax = ax_im\n",
    "    ax.grid(True)\n",
    "    #Label each of the cells with the row and the column:\n",
    "    if channel_names is not None:\n",
    "        for i in range(0, m.shape[0]):\n",
    "            if i < (m.shape[0] - 1):\n",
    "                ax.text(i - 0.3, i, channel_names[i], rotation=x_tick_rot)\n",
    "            if i > 0:\n",
    "                ax.text(-1, i + 0.3, channel_names[i],\n",
    "                        horizontalalignment='right')\n",
    "\n",
    "        ax.set_axis_off()\n",
    "        ax.set_xticks(np.arange(N))\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(channel_formatter))\n",
    "        fig.autofmt_xdate(rotation=x_tick_rot)\n",
    "        ax.set_yticks(np.arange(N))\n",
    "        ax.set_yticklabels(channel_names)\n",
    "        ax.set_ybound([-0.5, N - 0.5])\n",
    "        ax.set_xbound([-0.5, N - 1.5])\n",
    "\n",
    "    #Make the tick-marks invisible:\n",
    "    for line in ax.xaxis.get_ticklines():\n",
    "        line.set_markeredgewidth(0)\n",
    "\n",
    "    for line in ax.yaxis.get_ticklines():\n",
    "        line.set_markeredgewidth(0)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    #The following produces the colorbar and sets the ticks\n",
    "    if colorbar:\n",
    "        #Set the ticks - if 0 is in the interval of values, set that, as well\n",
    "        #as the maximal and minimal values:\n",
    "        if min_val < 0:\n",
    "            ticks = [color_min, min_val, 0, max_val, color_max]\n",
    "        #Otherwise - only set the minimal and maximal value:\n",
    "        else:\n",
    "            ticks = [color_min, min_val, max_val, color_max]\n",
    "\n",
    "        #This makes the colorbar:\n",
    "        cb = fig.colorbar(im, cax=ax_cb, orientation='horizontal',\n",
    "                          cmap=cmap,\n",
    "                          norm=im.norm,\n",
    "                          boundaries=np.linspace(color_min, color_max, 256),\n",
    "                          ticks=ticks,\n",
    "                          format='%.2f')\n",
    "\n",
    "    # Set the current figure active axis to be the top-one, which is the one\n",
    "    # most likely to be operated on by users later on\n",
    "    fig.sca(ax)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_all_connectivity_matrices():\n",
    "    from darwin.pipeline import ClassificationPipeline\n",
    "\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    results = {}\n",
    "    metrics = {}\n",
    "\n",
    "    param_grid = build_param_grid('selection_methods', 'similarity_measures')\n",
    "\n",
    "    n_combinations = len(selection_methods) * len(similarity_measures)\n",
    "\n",
    "    plot_count = 1\n",
    "    for paramidx, params in enumerate(param_grid):\n",
    "\n",
    "        selection_method   = params['selection_methods']\n",
    "        similarity_measure = params['similarity_measures']\n",
    "        value_range        = sm_value_ranges[similarity_measure]\n",
    "\n",
    "        connmats_grouppath = '{}/{}_{}'.format(aalconns_groupname, selection_method, similarity_measure)\n",
    "\n",
    "        print('Getting functional matrices data for {}.'.format(str(params)))\n",
    "        connectivities = get_connectivity_matrices(timeseries_h5path, connmats_grouppath, \n",
    "                                                   selection_method, similarity_measure)\n",
    "\n",
    "        n_subjects = len(connectivities)\n",
    "        for connidx, conn in enumerate(connectivities):\n",
    "            #plot_idx = plot_count  paramidx n_subjects\n",
    "            ax = plt.subplot(n_subjects, n_combinations, plot_count)\n",
    "            drawmatrix_channels(connectivities[conn], title=conn)#, color_anchor=value_range)\n",
    "            plot_count += 1\n",
    "            plt.show()\n",
    "            #print(plot_idx)\n",
    "\n",
    "\n",
    "#plot_all_connectivity_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!h5ls /Users/alexandre/Projects/bcc/cobre/cobre_partitioned_timeseries.hdf5/pipe_wtemp_noglob_aal_3mm_connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
